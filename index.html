<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
          content="Given a video and a text prompt, Dreamix edits the video while maintaining fidelity to color, posture, object size and camera pose, resulting in a temporally consistent video.">
    <meta property="og:title" content="Dreamix: Video Diffusion Models are General Video Editors"/>
    <meta property="og:description"
          content="Given a video and a text prompt, Dreamix edits the video while maintaining fidelity to color, posture, object size and camera pose, resulting in a temporally consistent video."/>
    <meta property="og:url" content="https://dreamix-video-editing.github.io"/>
    <meta property="og:image" content="static/image/og_banner_image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="630"/>


    <meta name="twitter:title" content="Dreamix: Video Diffusion Models are General Video Editors">
    <meta name="twitter:description"
          content="Given a video and a text prompt, Dreamix edits the video while maintaining fidelity to color, posture, object size and camera pose, resulting in a temporally consistent video.">
    <meta name="twitter:image" content="static/images/twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="keywords" content="Video diffusion models, video editing, dreamix, dreambooth, imagen-video">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>RemoCap: Disentangled Representation Learning for Motion Capture
    </title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
</head>

<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">RemoCap: Disentangled Representation Learning for Motion
                        Capture</h1>
                    <div class="is-size-5 publication-authors">
                        <!-- Paper authors -->
                        <span class="author-block">
                                Anonymous ECCV 2024
                            </span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block">Paper ID 10085</span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- Arxiv PDF link -->
                            <span class="link-block">
                                    <a href="#" target="_blank"
                                       class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>

                            <!-- Supplementary PDF link -->
                            <span class="link-block">
                                    <a href="#" target="_blank"
                                       class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Supplementary</span>
                                    </a>
                                </span>

                            <!-- Github link -->
                            <span class="link-block">
                                    <a href="#" target="_blank"
                                       class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>

                            <!-- ArXiv abstract Link -->
                            <span class="link-block">
                                    <a href="#>" target="_blank"
                                       class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                        </div>
<!--                        <img src="static/images/first.png" alt="Your Image Description"-->
<!--                             style="width: 100%; height: auto;margin-top: 1%;">-->
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        Current 3D human motion reconstruction methods from monocular videos rely on features within
                        the current reconstruction window, leading to distortion and deformations in the human
                        structure under local occlusions or blurriness in video frames. To estimate realistic 3D
                        human mesh sequences based on incomplete features, we propose Temporally-alignable
                        Probability Guided Graph Topological Modeling for 3D Human Reconstruction (ProGraph). For
                        missing parts recovery, we exploit the explicit topological-aware probability distribution
                        across the entire motion sequence. To restore the complete human, Graph Topological Modeling
                        (GTM) learns the underlying topological structure, focusing on the relationships inherent in
                        the individual parts. Next, to generate blurred motion parts, Temporal-alignable Probability
                        Distribution (TPDist) utilizes the GTM to predict features based on distribution. This
                        interactive mechanism facilitates motion consistency, allowing the restoration of human
                        parts. Furthermore, Herarchical Human Loss (HHLoss) constrains the probability distribution
                        errors of inter-frame features during topological structure variation. Our Method achieves
                        superior results than other SOTA methods in addressing occlusions and blurriness on 3DPW.
                        Codes are available in the appendix.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End paper abstract -->

<section class="section hero is-small">
    <div class="container is-max-desktop">
        <div class="columns is-centered">
            <div class="column is-full">
                <div class="content">
                    <h2 class="title is-3">Pipeline</h2>
                    <center>
                        <img src="static/images/pipeline.png" alt="Mixed Video-Image Finetuning"
                             class="center-image blend-img-background"/>
                    </center>
                    <div class="level-set has-text-justified">
                        <p>
                            Overview framework. This figure illustrates the pipeline of the RemoCap model. Feature maps
                            first undergo disentanglement by the Spatial Disentanglement (SD) and Temporal
                            Disentanglement (TD) modules. The disentangled features are then reweighted using a sigmoid
                            function before being decoded by a Transformer encoder to generate the final sequence of 3D
                            human mesh vertices.
                        </p>
                    </div>
                </div>
                <div style="border-bottom:3px solid #CCC"></div>
            </div>
        </div>
    </div>
</section>


<!-- Vid2vid carousel -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container  is-max-desktop">
            <h2 class="title is-3">Reconstruction</h2>
            <div id="results-carousel" class="carousel results-carousel">
                <div class="item item-video1">
                    <video poster="" id="header-video1" playsinline autoplay muted loop height="90%"
                           src="static/videos/video1.mp4">
                    </video>
                </div>
                <div class="item item-video2">
                    <video poster="" id="header-video2" playsinline autoplay muted loop height="90%"
                           src="static/videos/video2.mp4">
                    </video>
                </div>
                <div class="item item-video3">
                    <video poster="" id="header-video3" playsinline autoplay muted loop height="90%"
                           src="static/videos/video3.mp4">
                    </video>
                </div>
                <div class="item item-video4">
                    <video poster="" id="header-video4" playsinline autoplay muted loop height="90%"
                           src="static/videos/video4.mp4">
                    </video>
                </div>
                <div class="item item-video5">
                    <video poster="" id="header-video5" playsinline autoplay muted loop height="90%"
                           src="static/videos/video5.mp4">
                    </video>
                </div>
                <div class="item item-video6">
                    <video poster="" id="header-video6" playsinline autoplay muted loop height="90%"
                           src="static/videos/video6.mp4">
                    </video>
                </div>
            </div>
            <div style="border-bottom:3px solid #CCC"></div>
        </div>
    </div>
</section>
<!-- End vid2vid carousel -->

<!--&lt;!&ndash; Subject Driven Video Generation carousel &ndash;&gt;-->
<!--<section class="hero teaser">-->
<!--    <div class="hero-body ">-->
<!--        <div class="container is-max-desktop">-->
<!--            <h2 class="title is-3">More results</h2>-->
<!--            <div id="results-carousel" class="carousel results-carousel">-->
<!--                <div class="item item-video1">-->
<!--                    <video poster="" id="header-video1" autoplay muted loop playsinline height="100%"-->
<!--                           src="static/videos/video1.mp4">-->
<!--                    </video>-->
<!--                </div>-->
<!--                <div class="item item-video2">-->
<!--                    <video poster="" id="header-video2" autoplay muted loop playsinline height="100%"-->
<!--                           src="static/videos/video2.mp4">-->
<!--                    </video>-->
<!--                </div>-->
<!--                <div class="item item-video3">-->
<!--                    <video poster="" id="header-video3" autoplay muted loop playsinline height="100%"-->
<!--                           src="static/videos/video3.mp4">-->
<!--                    </video>-->
<!--                </div>-->
<!--                <div class="item item-video4">-->
<!--                    <video poster="" id="header-video4" autoplay muted loop playsinline height="100%"-->
<!--                           src="static/videos/video4.mp4">-->
<!--                    </video>-->
<!--                </div>-->
<!--                <div class="item item-video5">-->
<!--                    <video poster="" id="header-video5" autoplay muted loop playsinline height="100%"-->
<!--                           src="static/videos/video5.mp4">-->
<!--                    </video>-->
<!--                </div>-->
<!--                <div class="item item-video6">-->
<!--                    <video poster="" id="header-video6" autoplay muted loop playsinline height="100%"-->
<!--                           src="static/videos/video6.mp4">-->
<!--                    </video>-->
<!--                </div>-->
<!--            </div>-->
<!--            <div class="content" style="margin-top: 2%;">-->
<!--                <center>-->
<!--                    <img src="static/images/zhedang.png" alt="Mixed Video-Image Finetuning"-->
<!--                         class="center-image blend-img-background"/>-->
<!--                </center>-->
<!--                <div class="level-set has-text-justified">-->
<!--                    <p>-->
<!--                        The reconstruction results and probability distribution of human body parts during the-->
<!--                        prediction process.-->
<!--                    </p>-->
<!--                </div>-->
<!--            </div>-->
<!--            <div style="border-bottom:3px solid #CCC"></div>-->
<!--        </div>-->
<!--    </div>-->
<!--</section>-->
<!--&lt;!&ndash; End Subject Driven Video Generation carousel &ndash;&gt;-->

<section class="section hero is-small">
    <div class="container is-max-desktop">
        <div class="columns is-centered">
            <div class="column is-full">
                <div class="content">
                    <h2 class="title is-3">Comparisons</h2>
                    <center>
                        <img src="static/images/s13.png" alt="Mixed Video-Image Finetuning" width="800" height="500"
                             class="center-image blend-img-background"/>
                    </center>
                    <div class="level-set has-text-justified">
                        <p>
                            Comparison with GLoT.
                        </p>
                    </div>
                </div>
<!--                <div class="content">-->
<!--                    <center>-->
<!--                        <img src="static/images/human4d_hightlight.png" alt="Mixed Video-Image Finetuning"-->
<!--                             class="center-image blend-img-background"/>-->
<!--                    </center>-->
<!--                    <div class="level-set has-text-justified">-->
<!--                        <p>-->
<!--                            Comparison with 4DHumans.-->
<!--                        </p>-->
<!--                    </div>-->
<!--                </div>-->
            </div>
        </div>
    </div>
</section>


<!--BibTex citation -->
<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@article{RemoCap2024,
  title={RemoCap: Disentangled Representation Learning for Motion Capturen},
  author={},
  journal={},
  year={2024}
}</code></pre>
    </div>
</section>
<!-- End BibTex citation -->

<!--Acknowledgements -->
<section class="section" id="Acknowledgements">
    <div class="container is-max-desktop content">
        <h2 class="title">Acknowledgements</h2>
        <!-- We thank Ely Sarig for creating the video, Jay Tenenbaum for the video narration, Amir Hertz for the
        implementation of our eval baseline, Daniel Cohen-Or, Assaf Zomet, Eyal Segalis, Matan Kalman and Emily
        Denton for their valuable inputs that helped improve this work. -->
    </div>
</section>
<!--End Acknowledgements -->

<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">

                    <p>
                        This page was built using the <a
                            href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                            target="_blank">Academic Project Page Template</a>.
                        You are free to borrow the of this website, we just ask that you link back to this page in
                        the footer. <br> This website is licensed under a <a rel="license"
                                                                             href="https://creativecommons.org/licenses/by-sa/4.0/"
                                                                             target="_blank">Creative
                        Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p>

                </div>
            </div>
        </div>
    </div>
</footer>

<!-- Statcounter tracking code -->

<!-- Default Statcounter code for Dreamix
https://dreamix-video-editing.github.io -->
<script type="text/javascript">
    var sc_project = 12843789;
    var sc_invisible = 1;
    var sc_security = "e9c3bf5f";
</script>
<script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
<noscript>
    <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
            class="statcounter" src="https://c.statcounter.com/12843789/0/e9c3bf5f/1/" alt="Web Analytics"
            referrerPolicy="no-referrer-when-downgrade"></a></div>
</noscript>

<!-- End of Statcounter Code -->

</body>

</html>